{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24d21498",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import torchtext\n",
    "from torch.nn.functional import softmax as softmax\n",
    "from torch.nn.functional import log_softmax as logsoftmax\n",
    "from os.path import exists\n",
    "import sys\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ff9859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9732f838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ca0856b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c2dd9e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Current cuda device:  1\n"
     ]
    }
   ],
   "source": [
    "GPU_NUM = 1# 원하는 GPU 번호 입력\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device) # change allocation of current GPU\n",
    "\n",
    "print ('# Current cuda device: ', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d2e6926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# DEVICE 0: NVIDIA GeForce RTX 3090\n",
      "- Memory Usage:\n",
      "  Allocated: 0.0 GB\n",
      "  Cached:    0.0 GB\n",
      "\n",
      "# DEVICE 1: NVIDIA GeForce RTX 3090\n",
      "- Memory Usage:\n",
      "  Allocated: 0.0 GB\n",
      "  Cached:    0.0 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Conda1/lib/python3.9/site-packages/torch/cuda/memory.py:384: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def GPUreport():\n",
    "    if torch.cuda.is_available():\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f\"# DEVICE {i}: {torch.cuda.get_device_name(i)}\")\n",
    "            print(\"- Memory Usage:\")\n",
    "            print(f\"  Allocated: {round(torch.cuda.memory_allocated(i)/1024**3,1)} GB\")\n",
    "            print(f\"  Cached:    {round(torch.cuda.memory_cached(i)/1024**3,1)} GB\\n\")\n",
    "    else:\n",
    "        print(\"# GPU is not available\")\n",
    "GPUreport()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f44dd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (torch.device('cuda:1') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "#device = torch.device('cpu')#CPu로 할떄\n",
    "\n",
    "torch.set_printoptions(sci_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ab4ab15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.12.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchtext.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbc79252",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install datasets #기록용. 주석처리 풀지말것\n",
    "#!pip install torch\n",
    "#!pip install ipywidgets\n",
    "#!pip install spacy\n",
    "#!pip install torchtext\n",
    "#!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00157582",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wmt16 (/root/.cache/huggingface/datasets/wmt16/de-en/1.0.0/9e0038fe4cc117bd474d2774032cc133e355146ed0a47021b2040ca9db4645c0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef56ab17ecb4cf29a11e750dd4b9af3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'translation': {'de': 'Sein Auto lief noch in der Einfahrt.',\n",
       "  'en': 'His car was still running in the driveway.'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터셋 불러오기\n",
    "from datasets import load_dataset\n",
    "wmt16 = load_dataset('wmt16', 'de-en')\n",
    "wmt16['test'][33]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12573c97",
   "metadata": {},
   "source": [
    "데이터셋 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f603409b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'de': 'Obama empfängt Netanyahu', 'en': 'Obama receives Netanyahu'}\n",
      "{'de': 'Das Verhältnis zwischen Obama und Netanyahu ist nicht gerade freundschaftlich.', 'en': 'The relationship between Obama and Netanyahu is not exactly friendly.'}\n",
      "{'de': 'Die beiden wollten über die Umsetzung der internationalen Vereinbarung sowie über Teherans destabilisierende Maßnahmen im Nahen Osten sprechen.', 'en': \"The two wanted to talk about the implementation of the international agreement and about Teheran's destabilising activities in the Middle East.\"}\n",
      "{'de': 'Bei der Begegnung soll es aber auch um den Konflikt mit den Palästinensern und die diskutierte Zwei-Staaten-Lösung gehen.', 'en': 'The meeting was also planned to cover the conflict with the Palestinians and the disputed two state solution.'}\n",
      "{'de': 'Das Verhältnis zwischen Obama und Netanyahu ist seit Jahren gespannt.', 'en': 'Relations between Obama and Netanyahu have been strained for years.'}\n"
     ]
    }
   ],
   "source": [
    "t1= wmt16['test'][:5]\n",
    "for ding in t1['translation']:\n",
    "    print(ding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f64ffc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0351abb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'de': 'Rückbesinnung auf das sehr amerikanische Ideal der Arbeitsrechte als Menschenrechte',\n",
       "  'en': 'Reconnecting With the Very American Ideal That Labor Rights Are Human Rights'},\n",
       " {'de': 'Die Kongressabgeordneten Keith Ellison und John Lewis haben einen Gesetzesvorschlag eingebracht, um die Organisation von Gewerkschaften als Bürgerrecht zu etablieren.',\n",
       "  'en': 'Congressmen Keith Ellison and John Lewis have proposed legislation to protect union organizing as a civil right.'},\n",
       " {'de': '\"So wie Gewerkschaften sterben, sterben auch die Mittelklassejobs,\" sagte Ellison, ein Demokrat aus Minnesota und stellvertretender Vorsitzender des Progressive Caucus im Kongress.',\n",
       "  'en': '\"As go unions, so go middle-class jobs,\" says Ellison, the Minnesota Democrat who serves as a Congressional Progressive Caucus co-chair.'},\n",
       " {'de': 'Daher stelle ich stolz gemeinsam mit der Bürgerrechtsikone John Lewis das Mitarbeiterermächtigungsgesetz vor.',\n",
       "  'en': \"That's why I'm proud to introduce the Employee Empowerment Act with civil rights icon John Lewis.\"},\n",
       " {'de': 'Dieses bahnbrechende Gesetz gibt Arbeitern die gleichen rechtlichen Möglichkeiten bei Diskriminierung wegen der Organisation von Gewerkschaften wie bei anderen Formen der Diskriminierung - und stoppt so antigewerkschaftlich eingestellte Kräfte.',\n",
       "  'en': 'This ground-breaking legislation will give workers the same legal options for union organizing discrimination as for other forms of discrimination - stopping anti-union forces in their tracks'},\n",
       " {'de': 'Die Ergänzung des nationalen Arbeitsrechtsgesetzes, um eine Möglichkeit für einer Diskriminierung ausgesetzte Arbeitern zur Organisation einer Gewerkschaftsvertretung zu schaffen, um vor einem Zivilgericht um Gerechtigkeit zu klagen - und um Schadensersatz oder Strafgelder zu erhalten - ist eine sinnvolle und notwendige Initiative.',\n",
       "  'en': 'Amending the National Labor Relations Act to allow workers who face discrimination for engaging in union organizing to sue for justice in the civil courts - and to collect compensatory and punitive damages - is a sound and necessary initiative.'},\n",
       " {'de': 'Aber es ist mit Sicherheit keine radikale Initiative - jedenfalls nicht nach amerikanischen Standards.',\n",
       "  'en': 'But it in certainly not a radical initiative - at least by American standards.'},\n",
       " {'de': 'Tatsächlich ist die beste Art und Weise zum Verständnis dessen, was Ellison, Lewis und die weiteren Sponsoren ihrer Gesetzesvorlage vorschlagen, die Verbindung zurück zu einer sehr amerikanischen Idee.',\n",
       "  'en': 'Indeed, the best way to understand what Ellison, Lewis and the cosponsors of their legislation are proposing is as a reconnection with a very American idea.'},\n",
       " {'de': 'Trotz der Rückschläge, denen die Gewerkschaften in den vergangenen Jahren ausgesetzt waren - in Wisconsin, Michigan und anderen Staaten im ganzen Land - haben Amerikaner einst Länder in aller Welt dazu ermutigt, Arbeitsrechte anzuerkennen, auszuweiten und einzuhalten.',\n",
       "  'en': 'Despite the battering that unions have taken in recent years - in Wisconsin, Michigan and states across the country - Americans once encouraged countries around the world to embrace, extend and respect labor rights.'},\n",
       " {'de': 'Es gab eine Zeit, an die sich Millionen von Amerikanern noch erinnern, als dieses Land Demokratie, Redefreiheit, Pressefreiheit und das Vereinigungsrecht in einem Atemzug nannte.',\n",
       "  'en': 'There was a time, within the living memory of millions of Americans, when this country championed democracy, freedom of speech, freedom of the press and the right to organize in the same breath.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wmt16['validation'][:]['translation'][20:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08166a67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4548885,\n",
       " Dataset({\n",
       "     features: ['translation'],\n",
       "     num_rows: 2169\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['translation'],\n",
       "     num_rows: 2999\n",
       " }))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wmt16['train']), wmt16['validation'], wmt16['test'],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd65153d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDATA_PERCENTAGE = 0.005\\nimport spacy\\nfrom collections import Counter, OrderedDict\\nfrom torchtext.vocab import vocab\\n\\nspacy_en = spacy.load(\\'en_core_web_sm\\')\\nspacy_de = spacy.load(\\'de_core_news_sm\\')\\n\\ndef build_vocab(dataset, tokenizer, languege, percentage):\\n    wordCounter = Counter()\\n    with tqdm(total = math.trunc(len(dataset[\\'train\\'])*percentage/100)\\n              + math.trunc(len(dataset[\\'validation\\'])*percentage/100)\\n              + math.trunc(len(\\'test\\')*percentage/100)) as progressBar:\\n        for setNames in [\\'validation\\', \\'test\\', \\'train\\']:\\n            setSize = math.trunc(len(dataset[setNames])*percentage/100)\\n            totalsetSize = len(dataset[setNames])\\n            print(setNames, \"set\", setSize, totalsetSize, setSize*100/totalsetSize)\\n            proCounter = 0\\n            if setSize > 0: \\n                for translation in dataset[setNames]:#Each 문장 pair\\n                    wordCounter.update([token.text for token in tokenizer(translation[\\'translation\\'][languege])])\\n                    progressBar.update(1)\\n                    proCounter += 1\\n                    if proCounter==setSize:\\n                        print(setNames, proCounter, \"next set\")\\n                        break\\n    sorted_by_freq_tuples = sorted(wordCounter.items(), key=lambda x:x[1], reverse=True)\\n    ordered_Dict = OrderedDict(sorted_by_freq_tuples)\\n    return vocab(ordered_Dict, specials= [\\'<sos>\\', \"<eos>\",\"<pad>\"])\\nen_vocab = build_vocab(wmt16, spacy_en, \\'en\\', DATA_PERCENTAGE)\\nde_vocab = build_vocab(wmt16, spacy_de, \\'de\\', DATA_PERCENTAGE)\\ntorch.save(en_vocab, \"en_vocab dp = \"+str(DATA_PERCENTAGE)+\"percent.pt\")\\ntorch.save(de_vocab, \"de_vocab dp = \"+str(DATA_PERCENTAGE)+\"percent.pt\")\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#문장 토큰화\n",
    "#데이터셋이 너무 커서, 코드짜는 도중에는 1퍼센트만 사용하겠다.\n",
    "\"\"\"\n",
    "DATA_PERCENTAGE = 0.005\n",
    "import spacy\n",
    "from collections import Counter, OrderedDict\n",
    "from torchtext.vocab import vocab\n",
    "\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "spacy_de = spacy.load('de_core_news_sm')\n",
    "\n",
    "def build_vocab(dataset, tokenizer, languege, percentage):\n",
    "    wordCounter = Counter()\n",
    "    with tqdm(total = math.trunc(len(dataset['train'])*percentage/100)\n",
    "              + math.trunc(len(dataset['validation'])*percentage/100)\n",
    "              + math.trunc(len('test')*percentage/100)) as progressBar:\n",
    "        for setNames in ['validation', 'test', 'train']:\n",
    "            setSize = math.trunc(len(dataset[setNames])*percentage/100)\n",
    "            totalsetSize = len(dataset[setNames])\n",
    "            print(setNames, \"set\", setSize, totalsetSize, setSize*100/totalsetSize)\n",
    "            proCounter = 0\n",
    "            if setSize > 0: \n",
    "                for translation in dataset[setNames]:#Each 문장 pair\n",
    "                    wordCounter.update([token.text for token in tokenizer(translation['translation'][languege])])\n",
    "                    progressBar.update(1)\n",
    "                    proCounter += 1\n",
    "                    if proCounter==setSize:\n",
    "                        print(setNames, proCounter, \"next set\")\n",
    "                        break\n",
    "    sorted_by_freq_tuples = sorted(wordCounter.items(), key=lambda x:x[1], reverse=True)\n",
    "    ordered_Dict = OrderedDict(sorted_by_freq_tuples)\n",
    "    return vocab(ordered_Dict, specials= ['<sos>', \"<eos>\",\"<pad>\"])\n",
    "en_vocab = build_vocab(wmt16, spacy_en, 'en', DATA_PERCENTAGE)\n",
    "de_vocab = build_vocab(wmt16, spacy_de, 'de', DATA_PERCENTAGE)\n",
    "torch.save(en_vocab, \"en_vocab dp = \"+str(DATA_PERCENTAGE)+\"percent.pt\")\n",
    "torch.save(de_vocab, \"de_vocab dp = \"+str(DATA_PERCENTAGE)+\"percent.pt\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad6f48ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "spacy_de = spacy.load('de_core_news_sm')\n",
    "en_vocab = torch.load(\"./en_vocab dp = 10percent.pt\")\n",
    "de_vocab = torch.load(\"./de_vocab dp = 10percent.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec800270",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = []\n",
    "for sentence_pair in t1['translation']:\n",
    "    ttemp = [token.text for token in spacy_en(sentence_pair['en'])]\n",
    "    temp.append(ttemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92b20558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Obama', 'receives', 'Netanyahu'],\n",
       " ['The',\n",
       "  'relationship',\n",
       "  'between',\n",
       "  'Obama',\n",
       "  'and',\n",
       "  'Netanyahu',\n",
       "  'is',\n",
       "  'not',\n",
       "  'exactly',\n",
       "  'friendly',\n",
       "  '.'],\n",
       " ['The',\n",
       "  'two',\n",
       "  'wanted',\n",
       "  'to',\n",
       "  'talk',\n",
       "  'about',\n",
       "  'the',\n",
       "  'implementation',\n",
       "  'of',\n",
       "  'the',\n",
       "  'international',\n",
       "  'agreement',\n",
       "  'and',\n",
       "  'about',\n",
       "  'Teheran',\n",
       "  \"'s\",\n",
       "  'destabilising',\n",
       "  'activities',\n",
       "  'in',\n",
       "  'the',\n",
       "  'Middle',\n",
       "  'East',\n",
       "  '.'],\n",
       " ['The',\n",
       "  'meeting',\n",
       "  'was',\n",
       "  'also',\n",
       "  'planned',\n",
       "  'to',\n",
       "  'cover',\n",
       "  'the',\n",
       "  'conflict',\n",
       "  'with',\n",
       "  'the',\n",
       "  'Palestinians',\n",
       "  'and',\n",
       "  'the',\n",
       "  'disputed',\n",
       "  'two',\n",
       "  'state',\n",
       "  'solution',\n",
       "  '.'],\n",
       " ['Relations',\n",
       "  'between',\n",
       "  'Obama',\n",
       "  'and',\n",
       "  'Netanyahu',\n",
       "  'have',\n",
       "  'been',\n",
       "  'strained',\n",
       "  'for',\n",
       "  'years',\n",
       "  '.']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp#Not wordpiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5e1c17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.pt exists\n"
     ]
    }
   ],
   "source": [
    "#실제 데이터 생성. 데이터: 사전인 en_vocab 과 de_vocab\n",
    "#pad\n",
    "FILENAME_DATA = \"data.pt\"\n",
    "\n",
    "SOS_IDX = en_vocab[\"<sos>\"]\n",
    "EOS_IDX = en_vocab[\"<eos>\"]\n",
    "PAD_IDX_EN = en_vocab[\"<pad>\"]\n",
    "PAD_IDX_DE = de_vocab[\"<pad>\"]\n",
    "\n",
    "def data_process(dataset):\n",
    "    tokenized_data = []\n",
    "    for sentence_pair in dataset['translation']:\n",
    "        de_tensor_ = torch.tensor(de_vocab([token.text for token in spacy_de(sentence_pair['de'])]), dtype=torch.long)\n",
    "        en_tensor_ = torch.tensor(en_vocab(['<sos>',]+[token.text for token in spacy_en(sentence_pair['en'])]+['<eos>']), dtype=torch.long)\n",
    "        tokenized_data.append((de_tensor_, en_tensor_))\n",
    "    return tokenized_data\n",
    "\n",
    "\n",
    "if exists(FILENAME_DATA):\n",
    "    print(FILENAME_DATA, \"exists\")\n",
    "    sample_data = torch.load(\"./\"+FILENAME_DATA)\n",
    "else:\n",
    "    sample_data = data_process(wmt16['train'][:math.trunc(len(wmt16['train'])*9.99/100)])\n",
    "    #sample_data = data_process(wmt16['train'][:10000])\n",
    "    torch.save(sample_data, \"data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6184a689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpusize(tensor):\n",
    "    return tensor.element_size() * tensor.nelement()/1e+6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fe17c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def generate_batch(data_batch):\n",
    "    de_batch, en_batch = [], []\n",
    "    for (de_item, en_item) in data_batch:\n",
    "        en_batch.append(en_item)\n",
    "        de_batch.append(de_item)\n",
    "    de_batch = pad_sequence(de_batch, padding_value=PAD_IDX_DE).transpose(0,1)\n",
    "    en_batch = pad_sequence(en_batch, padding_value=PAD_IDX_EN).transpose(0,1)\n",
    "    return de_batch, en_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b714a3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  910,     3,   151,     5,   416,    12,    20,  2486, 14229,  1952,\n",
       "           149,     3,   407,    24,    23,    12,   215,     3,    47,   356,\n",
       "         47814,     4,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2],\n",
       "        [ 5223,  2826,    45,   279,     3,    20, 20996,  8292,  2242,     3,\n",
       "           627,   636,     6,  2560,   102, 16628,   284,   412, 55457,  6836,\n",
       "             4,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2],\n",
       "        [   34,   157,  2580,     3,    75,    24,     5,   557, 16629,     3,\n",
       "            63,    10,   984,     6,   527,     3,    87, 11084,     3,   175,\n",
       "         21000,  1251,     9,   191,     4,     2,     2,     2,     2,     2,\n",
       "             2],\n",
       "        [   39,    58,     3,    24,   616,   103,    73,     3,  3571,   661,\n",
       "            59,    98,  5264,    13,     4,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2],\n",
       "        [  804,   219,    63,   146,    94,   187,   342,    41,    16, 91408,\n",
       "          2729,     3,    16, 10039,    21,   290,     3,    72,    94,    20,\n",
       "           377,  6257, 20252,   517,  2616,     4,     2,     2,     2,     2,\n",
       "             2],\n",
       "        [  451,    32,   142,   219,    63,    96,  1792,     3,     5,    16,\n",
       "         15008,    17,   192,   762,     6,   601,    42,   596,   381,     3,\n",
       "             5,  1174,  1792,    41,     5,  3355,    17,   192,    43, 42653,\n",
       "             4],\n",
       "        [13758,    59,     3,  2136,   290,     5,  7231,     3,    72,    23,\n",
       "            38,    78,  1341,  3770,   136,     3,    81,  5120,  9136, 47870,\n",
       "            19, 92052, 12069,    21,     4,     2,     2,     2,     2,     2,\n",
       "             2],\n",
       "        [ 2264,    51,   145,     3,   299,   352,     5,  4211,   173,   483,\n",
       "             3, 91611,     3,     9,  2178,     3,     5,     8,  6922,   914,\n",
       "         13967,   149,     4,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2],\n",
       "        [  323,     6,   403,   678,     5,  2388,     4,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2],\n",
       "        [  685,   613,     6,  2256,   109,   521,    98,    74,    43,     5,\n",
       "          2819,    84,     6,    55,    50,     4,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dataloader = DataLoader(sample_data, batch_size=10, shuffle=True, collate_fn=generate_batch)\n",
    "sample_batch=None\n",
    "for batch in sample_dataloader:\n",
    "    \n",
    "    sample_batch=batch\n",
    "    break\n",
    "sample_batch[0]#독일어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d5560d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,    66,  1106,   189,     7,     3,  3449,   219,     8,     7,\n",
       "             3, 12403,     8, 22656,  6088,     5,  2101,     3,   407,    15,\n",
       "             3,   556,   392,  2683,    22,  3089,     4,    13,   153,    24,\n",
       "            11,    92,     7,   783,     3,   139,  1962,  2023,     5,     1,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2],\n",
       "        [    0,   443,    10,    88,     4,   712,    55,   810,    77,     3,\n",
       "          1299,    14,    12,  7785,  1739,     6,  2130,     5,    70,    75,\n",
       "           400,     4,    12,  1121,    36,    97,  5828,    11,     7,  1768,\n",
       "           258,    54,    20,     3,  1121,    11,  3466,     5,     1,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2],\n",
       "        [    0,   103,  2887,    85,    32,    43,     4,    13,    98,   727,\n",
       "            13,    22,    48,   237,     3,   380,     7,   100,    12,   303,\n",
       "          7527,  2155,    34,     3,   239,     6,   212,   148,  8406,    36,\n",
       "            97,  1092,     4,   308,    23,    13,    30,     4,     6,   176,\n",
       "             4,  2417,    26,    39,   567,   436,     7,     3,   283,  1351,\n",
       "             5,     1],\n",
       "        [    0,    32,    43,     4,    16,    58,    11,   432,    47,     4,\n",
       "           502,     4,    18,    83,    56,   119,    16,     5,     1,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2],\n",
       "        [    0,    13,   101,   454,    18,    44,  1562,   438,     3,   675,\n",
       "             6,   533,    10,    18,    21,     9,  1379,     6, 11935,    81,\n",
       "            18,   229,   329,    16,   908,     6,   391,     4,    23,  1424,\n",
       "             7,    17,   315,   309,     5,     1,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2],\n",
       "        [    0,    41,   101,   438,    10,     3,   925,  6526,     6,     3,\n",
       "            53,    11,    34,   262,   289,   491,     7,     3,   141,    39,\n",
       "           422,   211,   669,     3,    53,    36,    97,  3197,    25,    12,\n",
       "           573,  1272,     5,     1,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2],\n",
       "        [    0, 13785,    56,  1536,     4,     9,     3,   244,   396,    24,\n",
       "            11,   156,    10,    14,   414,  2479,     6,   520,     4,     3,\n",
       "          5024,   732,    30,    17, 14832,    27,  6935,   660,  1371,  1046,\n",
       "          3458,     7,   593,    19,  8402,   732,  7217,     5,     1,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2],\n",
       "        [    0,    13,   187,    52,    57,    20,   691,    81,    13,   100,\n",
       "           203,   775,     6,     3,  3049,     9,    80,   515,     4, 16212,\n",
       "             4,    23,    22,  2365,  1320,  1657,     5,     1,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2],\n",
       "        [    0,    29,   283,   647,    11,  1050,  2650,   103,  1114,    19,\n",
       "         27332,    85,     5,     1,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2],\n",
       "        [    0,  1255,     4,    76,    25,    12,  1883,    11,    12,   226,\n",
       "           363,    56,   119,   133,     3,  2422,   106,    67,    62,     5,\n",
       "             1,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e2f01cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HYPERPARAMETERS\n",
    "embed_size = 50\n",
    "hidden_size_ex = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40beda34",
   "metadata": {},
   "outputs": [],
   "source": [
    "de_word_size = len(de_vocab)\n",
    "en_word_size = len(en_vocab)\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embed = torch.nn.Embedding(de_word_size, embed_size).to(device = device)#word_sizexembed size matrix. 정수->벡터 함수\n",
    "        self.LSTM = torch.nn.LSTM(input_size = embed_size , hidden_size= hidden_size_ex, batch_first=True).to(device = device)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = x.to(device = device)#x shape: batch*sentence_size\n",
    "        #print(\"Encoder input:\", x)#debug\n",
    "        x = self.embed(x).to(device = device)#x.shape = batchxsentence size(문장의 토큰 개수)x embed_size\n",
    "        #print(token.unsqueeze(0).unsqueeze(0))#1x1x4\n",
    "        output, final_status = self.LSTM(x)\n",
    "        #print(\"Encoder output:\", final_status)#debug\n",
    "        return output, final_status# shape: batch x sentence_size(LSTM이 돈 횟수) x hidden_size_sx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d959b70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embed = torch.nn.Embedding(en_word_size, embed_size).to(device = device)#word_sizexembed size matrix. 정수->벡터 함수\n",
    "        self.LSTM = torch.nn.LSTM(input_size = embed_size , hidden_size= hidden_size_ex, batch_first=True).to(device = device)\n",
    "    def forward(self, x, final_encoder_state):\n",
    "        x = x.to(device = device)#x shape: batch*sentence_size\n",
    "        #print(\"Decoder input:\", x)#debug\n",
    "        x = self.embed(x)#x.shape = batchxsentence size(문장의 토큰 개수)x embed_size\n",
    "        output, final_decoder_status = self.LSTM(x, final_encoder_state)\n",
    "        #print(\"Decoder output:\", final_decoder_status)#debug\n",
    "        return output, final_decoder_status# shape: batch x sentence_size(LSTM이 돈 횟수) x hidden_size_sx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c8f370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention_LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.decoder=Decoder()\n",
    "        self.encoder=Encoder()\n",
    "        self.hiddenstate = nn.Sequential(nn.Linear(hidden_size_ex*2, hidden_size_ex), nn.BatchNorm1d(hidden_size_ex)).to(device = device)\n",
    "        self.outputLayer = nn.Linear(hidden_size_ex, en_word_size).to(device = device)\n",
    "        \n",
    "    def forward(self, x):#x=(de,en) sentence imbedding\n",
    "        tf = random.randrange(2)\n",
    "        ground_truth = x[1].to(device = device)\n",
    "        #print(\"ALSTM en ground_truth:\", ground_truth)#debug\n",
    "        en_sentence_size = x[1].shape[1]\n",
    "        #print(\"ALSTM en ground_truth sentence size:\", en_sentence_size)#debug\n",
    "        en_generated = torch.zeros((ground_truth.shape[0],1),requires_grad = False, dtype=torch.int64).to(device=device)\n",
    "        output= None\n",
    "        de_batch = x[0].to(device = device)\n",
    "        #print(\"ALSTM de input:\", de_batch)#debug\n",
    "        encoder_result, final_encoder_status = self.encoder(de_batch)#batch*sentence size*embedding\n",
    "        final_status = final_encoder_status #state for decoder...     \n",
    "        for iteration in range(1, en_sentence_size):\n",
    "            decoder_result, final_status = self.decoder(en_generated[:,-1].unsqueeze(1), final_status)#decoder result: batch*1*hidden_status\n",
    "            attention_score = torch.matmul(encoder_result,decoder_result.transpose(1,2))#decoder_result를 column vector로 바꿔주었다. final shape = batch*encoder sentence size* 1(디코더에는 한 번에 한 token만 넣어주므로..)\n",
    "            attention_distribution = softmax(attention_score, dim=1)\n",
    "            #print(\"ALSTM attention_distribution:\", attention_distribution)#debug\n",
    "            attention_value = torch.sum(encoder_result * attention_distribution, dim=1).unsqueeze(1)#아다마르 곱 후 unsqueeze 로 batch*1*hidden_size 로 바꿔준다\n",
    "            #print(\"ALSTM attention_value:\", attention_value)#debug\n",
    "            att_dec_concat = torch.cat((attention_value, decoder_result), dim = 2).squeeze(1)#batch*hidden_sie*2\n",
    "            #print(\"ALSTM input for final Linear layer:\", att_dec_concat)#debug\n",
    "            final_vector = torch.tanh(self.hiddenstate(att_dec_concat))#batch*hidden_s\n",
    "            a_output = self.outputLayer(final_vector)#batch*en_word_size\n",
    "            #print(\"ALSTM output of final Linear layer:\", output)#debug\n",
    "            #output_softmax = softmax(output, dim=1)\n",
    "            #output_lsm = logsoftmax(output,dim=1)\n",
    "            #print(\"ALSTM Logsoftmax:\", output_lsm)#debug\n",
    "            \n",
    "            a_output_argmax = a_output.argmax(dim=1).view(-1,1)\n",
    "            current_truth = ground_truth[:,iteration]\n",
    "            \n",
    "            #print(iteration, output_softmax[:,current_truth].shape)\n",
    "            #print(current_truth)\n",
    "\n",
    "            if self.training == True:#what to do in training mode -> model.train()...\n",
    "                if  tf == 1:\n",
    "                    en_generated = torch.cat((en_generated, current_truth.unsqueeze(1)), dim=1)#teacher forcing\n",
    "                else:\n",
    "                    en_generated = torch.cat((en_generated, a_output_argmax), dim=1)#Non_teacher_forcing\n",
    "            else:\n",
    "                en_generated = torch.cat((en_generated, a_output_argmax), dim=1)\n",
    "            #prob_truth = output_lsm[[idx for idx in range(output_lsm.shape[0])],current_truth].unsqueeze(1)\n",
    "            if output is None:#shape = batch*sentence_size2\n",
    "                output = a_output.unsqueeze(1)#batch*1*en 사전크기\n",
    "                #print(output.shape)\n",
    "            else:\n",
    "                output = torch.cat((output, a_output.unsqueeze(1)),dim=1)\n",
    "                #print(output.shape)\n",
    "            #print(en_generated)\n",
    "        #print(\"tensor size of output: \", gpusize(output))# debug\n",
    "        return en_generated, output\n",
    "sample_LSTM = Attention_LSTM()\n",
    "sample_LSTM.eval()\n",
    "sample_generated, sample_output = sample_LSTM(sample_batch)\n",
    "sample_LSTM.train()\n",
    "sample_LSTM = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68e61098",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([380])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_generated.reshape(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e329debf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([370, 59564])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_output.reshape(-1,en_word_size).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b5a0dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(optimizer, model, loss_fn, train_loader):\n",
    "    model.train()\n",
    "    loss_train = 0.0\n",
    "    for batch in train_loader:\n",
    "        generated_sentence, logit = model(batch)\n",
    "        ground_truth = batch[1].to(device = device)\n",
    "        ground_truth = torch.split(ground_truth, [1,ground_truth.shape[1]-1], dim=1)[1]#train 이라서 ground truth. 제일 처음의 0을 제거함.\n",
    "        ground_truth = ground_truth.reshape(-1)\n",
    "        logit = logit.reshape(-1,en_word_size)\n",
    "        mask = ground_truth != 2# 2인경우에는 0\n",
    "        #print(generated_sentence.dtype)\n",
    "        #print(prob_output)#debug\n",
    "        #logsoftmax_stack = logsoftmax_stack.to(device=device)\n",
    "        #loss = loss_fn(logsoftmax_stack.reshape(-1,logsoftmax_stack.shape[-1]), generated_sentence.reshape(-1))\n",
    "        loss = loss_fn(logit, ground_truth)*mask\n",
    "        #print(loss, mask)\n",
    "        loss = loss.mean()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_train += loss\n",
    "        #print(\"loss:\",loss)\n",
    "        #break\n",
    "    loss_train = loss_train/len(train_loader)\n",
    "    torch.save(model.state_dict(), FILENAME_PARAMETERS)\n",
    "    #print(\"batchloss\",loss_train)\n",
    "    return loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3823901",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n",
      "param exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Conda1/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "FILENAME_PARAMETERS = \"seq2seq_param.pt\"\n",
    "LR = 0.004\n",
    "EPOCH = 0\n",
    "print(device)\n",
    "#train----------------------------------\n",
    "model = Attention_LSTM()\n",
    "if exists(FILENAME_PARAMETERS):\n",
    "    model.load_state_dict(torch.load(\"./\" + FILENAME_PARAMETERS))\n",
    "    print(\"param exists\")\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay = 0.004)\n",
    "loss_fn = nn.CrossEntropyLoss(reduce = False, reduction = 'none')\n",
    "#train this fold\n",
    "train_loader = DataLoader(sample_data, batch_size=80, shuffle=True, collate_fn=generate_batch)\n",
    "for epoch in range(EPOCH):\n",
    "    result = training_loop(optimizer, model, loss_fn, train_loader)\n",
    "    print(\"epoch\", epoch, \" loss:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a63e21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "GPUreport()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef0b011",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), FILENAME_PARAMETERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0276bd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attention_LSTM(\n",
       "  (decoder): Decoder(\n",
       "    (embed): Embedding(59564, 50)\n",
       "    (LSTM): LSTM(50, 25, batch_first=True)\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (embed): Embedding(175559, 50)\n",
       "    (LSTM): LSTM(50, 25, batch_first=True)\n",
       "  )\n",
       "  (hiddenstate): Sequential(\n",
       "    (0): Linear(in_features=50, out_features=25, bias=True)\n",
       "    (1): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (outputLayer): Linear(in_features=25, out_features=59564, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a7fea65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_eval = model(sample_batch)[0].to(device = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38a3b068",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6ee9349",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = en_vocab.get_itos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ffd572d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_to_string(tensor):\n",
    "    tensorlist = tensor.tolist()\n",
    "    strings = []\n",
    "    for string in tensorlist:\n",
    "        temp1 = ''\n",
    "        for letter in string:\n",
    "            if letter:\n",
    "                temp1 += ' ' + dic[letter]\n",
    "        strings.append(temp1)\n",
    "    return strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3ec3880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Obnova is to the negotiations negotiations in the negotiations negotiations in the negotiations negotiations in the negotiations negotiations in the negotiations in the negotiations in the negotiations and the negotiations negotiations in the negotiations and the negotiations negotiations in the negotiations and the negotiations negotiations in the negotiations and the negotiations',\n",
       " ' publication are to the reversed of the the of the the of the of the of the of the of the of the of the the of the of the of the of the of the of the of the of the of the of the of the of the of',\n",
       " ' rapporteurs agree with Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs Mrs',\n",
       " ' President Mr President , I - that , that is , , that , that , that , that , that , that , that , that , that , that , that , that , that , that , that , that , that , that , that , that',\n",
       " ' assurance of we therefore therefore to the that is is is is that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that',\n",
       " ' Experts the the the the Secretariat of the the the the the Secretariat of the the the the the Secretariat of the the the the the Secretariat of the the the the the Secretariat of the the the the the Secretariat of the the the the the Secretariat of the the',\n",
       " ' vessel , is . , , , , is . . <eos> , , - - , , - - , , - - , , - - , , - - , , - - , , - - , , - - , , - - , , -',\n",
       " ' forgive the region , , Lorraine , Lorraine , have suffered , , Lorraine , Lorraine , have have suffered , , Lorraine , have suffered , , Lorraine , have have suffered , in suffered , , Lorraine , have suffered , , , have have Portugal , Lorraine ,',\n",
       " ' plant on Time Question Time Question Time Question Time Question Time Question Time Question Time Question Time Question Time Question Time Question Time Question Time Question Time Question Time Question Time Question Time Question Time Question Time Question Time Question Time Question Time Question Time Question Time Question Time Question Time',\n",
       " ' appalling Europe is a a a a a a a the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_to_string(sample_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9abb6314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' This applies both to the interim agreement and to the Hebron and Wye Agreements . While the negotiations on the final peace settlement have begun , I think it is important to keep the two processes apart . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>',\n",
       " \" At that time , she was talking about the desire for a reversed burden of proof . In other words , a product ' s manufacturer is to demonstrate whether or not the product is hazardous . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\",\n",
       " \" ( NL ) Mr President , I am pleased I have been given the opportunity to make a few introductory remarks at the end of rapporteur Mrs Berger ' s speech , after which I will , of course , listen with all due attention to the next speakers . <eos>\",\n",
       " ' Mr President , this report is positive but , actually , we need more than this . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>',\n",
       " ' I therefore feel we must carefully consider the balance of power that we are in danger of upsetting if we put forward this type of reform , which appears to be quite specific . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>',\n",
       " \" We therefore consider that the General Secretariat of the Council is at present making available to the public all essential information regarding the Council ' s functions as a legislative body . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\",\n",
       " ' Put more strongly , in the long term it is possible that for large numbers of funds , the Tobin tax will be evaded by shifting foreign exchange rate transactions to off - shore tax havens . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>',\n",
       " ' I hope you do not mind if I make particular mention of the forests in my region , Lorraine , which have suffered enormous destruction . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>',\n",
       " ' The next item is Question Time ( B5 - 0003/2000 ) . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>',\n",
       " ' Moreover , Europe as a continent is a great deal more than just the fifteen EU Member States . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_to_string(sample_batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa59ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = next(model.decoder.embed.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5f6fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "emb[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77f6574",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eb8316",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3145abe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Conda1] *",
   "language": "python",
   "name": "conda-env-Conda1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
